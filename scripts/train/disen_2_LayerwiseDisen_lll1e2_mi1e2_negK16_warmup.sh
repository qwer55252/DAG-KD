python train.py \
  --wandb_run disen_2_LayerwiseDisen_lll1e2_mi1e2_negK16_warmup \
  --out outputs/disen/disen_2_LayerwiseDisen_lll1e2_mi1e2_negK16_warmup \
  --data_script ./librispeech_asr.py \
  --data_cfg train_100 \
  --train_split train.clean.100 \
  --val_split dev.clean \
  --test_split test.clean \
  --teacher_name stt_en_conformer_ctc_small \
  --use_ctc True \
  --use_logit_kd True \
  --use_layer_kd False \
  --use_flow False \
  --use_diffkd False \
  --use_disent False \
  --disent_spk_layers "4" \
  --disent_txt_layers "16" \
  --flow_steps 8 \
  --batch_size 32 \
  --epochs 100 \
  --gpus 1 \
  --use_txt_spk_probe True \
  --txt_probe_lambda 1.0 \
  --txt_probe_lr 0.001 \
  --disen_mi_pairs "ts,tp" \
  --disen_lll_weight 0.01 \
  --disen_mi_weight 0.01 \
  --use_stu_spk_adv False \
  --stu_spk_adv_lambda_max 0.01 \
  --stu_spk_adv_warmup_steps 2000 \
  --use_layerwise_disent True \
  --use_layerwise_flow True \
  --use_layerwise_diffkd True \
  --layer_list_for_disent "4,8,12,16" \
  --neg_K 16 \
  --mi_warmup_steps 5000 \
  --mi_lambda_max 0.01 \
  --lll_lambda_max 0.01

